---
title: "The basics of Calculus with nonstandard numbers"
execute:
    cache: true
bibliography: quartoexample.bib
---

# Teaching Derivatives

To demonstrate the basics of how Quarto works, we'll write a simple document describing how calculus works using nonstandard analysis. We will include links to external material, figures generated by Julia, a bibliography entry, and footnotes with details appropriate for a subset of the audience. 

Students from 8th grade onward can understand the basic ideas behind Calculus, usually what they lack is the ability to do sufficient algebra to solve assigned problems. But the basic concepts are pretty easy to teach. In particular, it's easy to teach if we accept that we can invent a number system that makes calculus simple.

The [Internal Set Theory (IST)](https://web.math.princeton.edu/~nelson/books/1.pdf) was invented by Edward Nelson as a simplified sort of Nonstandard Analysis compared to the original ideas of Abraham Robinson. Nelson was a mathematician who worked at Princeton and you can read more about the [details of his theory in the original paper](https://projecteuclid.org/journals/bulletin-of-the-american-mathematical-society-new-series/volume-83/issue-6/Internal-set-theory-A-new-approach-to-nonstandard-analysis/bams/1183539849.full) [@nelsonIST] or in his other publications, but we will describe the basics in a manner that might be usable to teach a high school student.

## IST defines a new property of numbers

In IST, some numbers are said to be "Standard". Roughly, a number is standard if there is some usual mathematical formula which defines it. For example $\pi$ is standard because it's defined by the formula $\pi \equiv x : x \in [1,6] \land \sin(x) = 0$. A number is nonstandard, roughly, if you can't define it without making use of the new property "standard" $st()$ in its definition. You can think of the property "standard" as giving us a finer detailed microscope to look at numbers with. In IST the axioms imply there are some _nonstandard_ numbers as well. 

We can prove from the axioms that there exists a nonstandard positive integer [^existsNS] bigger than all standard integers. We therefore call it "unlimited" which roughly means "infinite". In other words, we now have a way to talk about infinitely large quantities, quantities so big that we can't write down any standard formulaic definition of how big they are. For example $10^{100}$ is a mere trifle compared to a nonstandard integer. Even $10^{10^{100}}$ is an infinitesimal fraction of a nonstandard integer. This is why nonstandard integers are called "infinite" because all standard integers are so much smaller than they are.

If N is a nonstandard integer, then the quantity $\epsilon = 1/N$ must be very small. In fact, it is not zero, but it is closer to zero than any standard number. It's an _infinitesimal_ number, a number so small that we can't distinguish it from zero without the help of the extra axioms of IST. [^proofInftsml]

Let's consider the function sin(x) which measures the ratio of two lengths, the y leg of the triangle shown below, divided by the hypotenuse which is also the radius of the circle r. The argument or input to the function $\sin$ is a symbol $\theta$ that represents the distance along the curve from the x axis as a fraction of the radius r. This is how we represent angles in modern mathematics, rather than in degrees. [Degrees](https://en.wikipedia.org/wiki/Degree_(angle)) were likely invented by Babelonians for the convenience of constructing calendars and surveying with more primative instruments, but radians (which is what we call the measure $\theta$) have very good mathematical properties for measuring angles for use in calculus.

```{julia}

using StatsPlots, Printf

x = collect(-pi:0.01:pi)
plot(cos.(x),sin.(x),size=(400,400); label=false, legend=:topleft,title="sin(θ) = y/r")
plot!([0,cos(1.0)],[0,sin(1)]; label="hypotenuse",linewidth=3)
plot!([0,cos(1.0)],[0,0]; label="x leg", linewidth=3)
plot!([cos(1.0),cos(1.0)],[0,sin(1.0)]; label="y leg",linewidth=3)
xarc = collect(0.0:.01:1.0)
plot!(cos.(xarc),sin.(xarc); linewidth=3, label="angle alpha")
annotate!(.25,-.15,text("x"))
annotate!(.7,.3,text("y"))
annotate!(.15,.5,text("r"))
annotate!(1,.7,text("θ"))

```

The function $\sin(\theta)$ takes an angle $\theta$ as input, and outputs the ratio of the purple side of the triangle y, to the radius r. Let's see what this function looks like for different values of the angle between -3 and 3 (a negative angle means one that turns clockwise, positive angles turn counterclockwise)


```{julia}

plot(x,sin.(x); size=(400,400), legend=false,xlim=(minimum(x),maximum(x)),ylim=[-1,1],title="A plot of sin(x) with sin(1.0)")
scatter!([1.0], [sin.(1.0)])
annotate!([-1],[sin(1.0)],text(@sprintf("sin(1.0) ~ %.3f",sin(1.0))))
```

# Finding rates of change

We see in the above graph that when the arc length is 1.0 the vertical leg of the triangle is a little less than 1.0, or approximately 0.841. We can also see that if we move to a slightly larger value of x, we will get a slightly larger value of $\sin(x)$. Let's zoom into the region around x=1.0

```{julia}
xzoom = collect(1:.01:1+.1)
plot(xzoom,sin.(xzoom);size=(400,400),label="sin(x)",legend=:topleft,linewidth=2)
plot!([1.0,1.1],[sin(1.0),sin(1.1)],label="line between (1,sin(1)) and\n(1.1,sin(1+.1))",linewidth=2)
```

We can see that the straight line (red) between (1,sin(1)) and (1.1,sin(1.1)) is not the same as the curve sin(x) (blue), which actually rises a little above this straight line. 

# The core idea of Differential Calculus: find the best line to approximate a function

The idea behind differential calculus is as follows: 

If someone gives us a function $f(x)$ and this function is "differentiable" at a point $x^*$ that means there's a line through $(x^*,f(x^*))$ with a slope $f'(x^*)$ and this line with this particular slope will approximate the function so well, that if we move over by an infinitesimal amount $dx$ the error between the actual function and the line will be so small that as a fraction of the amount we moved, $dx$, it will still be infinitesimal.

$$ \frac{f(x^*+dx) - (f(x^*) + f'(x^*)((x^*+dx)-x^*))}{dx} \cong 0$$

The expression $\cong 0$ means that the difference from zero is infinitesimal.

Here we can see that a line through the point with the slope equal to $f'(x)$ produces a "tangent line" which just touches the curve in a way that it is maximally close to the curve in the neighboring points.

```{julia}

x = collect(0.5:0.05:1.5)
plot(x,sin.(x); title="sin(x) and the tangent line to it at x = 1.0",legend=false)
plot!(x,sin(1.0) .+ cos(1.0)*(x.-1.0))

```


Simplifying the previous equation somewhat we have:

$$\frac{f(x^*+dx)-f(x^*)}{dx} - \frac{f'(x^*)dx}{dx} \cong 0$$

since in IST the quantity $dx$ is an infinitesimal number, and infinitesimal numbers behave the same arithmetical rules as standard numbers, we have $dx/dx = 1$, so we can write:

$$\frac{f(x^*+dx)-f(x^*)}{dx} \cong f'(x^*)$$

Therefore we define the **derivative of the function f(x)**, which we call $f'$ to be the "standard part" of the ratio, and we can define it like that as a function of x. The "standard part" $st()$ is the "nearest standard number" which is guaranteed to exist and be unique unless the quantity is bigger than some nonstandard integer (ie. the quantity is infinite).

$$f'(x) \equiv st\left(\frac{f(x+dx) - f(x)}{dx}\right)$$

The derivative tells us the slope of the "best approximating line" through the point $(x,f(x))$. Since that line increases at a rate equal to its slope, we say that the rate of change of the function is also equal to that slope. For infinitesimal increases in x, the function will increase by $f'(x)dx$.

Note also that in this definition dx is a positive infinitesimal. If the function behaves the same when we slightly increase the x value as when we slightly decrease the x value then the derivative is continuous. Functions with a "cusp" have discontinuous derivatives: they jump from one slope to another suddenly.

```{julia}
#| label: fig-charts
#| fig-cap: "abs(sin(x)) has a cusp at pi"
#| fig-alt: "a plot of abs(sin(x)) showing a cusp at x=pi"
x = 0:0.05:6
plot(x,abs.(sin.(x)))

```

The function abs(sin(x)) has a cusp at $\pi$. The function is decreasing strongly for values below $\pi$ but increasing strongly for values above $\pi$. The transition is abrupt as we pass the value $x=\pi$.

# Integration / adding up

The "big idea" of differential calculus is creating a line which is the best approximation to a differentiable function by using the slope of the line that makes the approximation error infinitesimal even as a fraction of the deviation from the tangent point. That slope describes "how fast" the function is changing.

There is one other "big idea" in calculus... adding an enormous quantity of small things up to find a total equal to the value of something important.

Let's look at our $\sin(x)$ function again, and ask how big is the shaded area?

```{julia}

x = collect(0:.05:3)
plot(x,sin.(x))
plot!(0:.05:2,sin.(0:.05:2),fill=(0,"red"))


```

We know how to calculate the area of a rectangle (base times height) or a triangle (half base times height), but the area of an arbitrary shaped region is not so easy to calculate.

Let's try to approximate it by breaking the area into 4 rectangles.

```{julia}
plot(x,sin.(x); label="sin(x)", linewidth=2)

barx = collect(0.25:0.5:1.75)
bary = [sin(0.5),sin(1.0),sin(1.5),sin(2.0)]

Aest = sum(0.5 * bary[i] for i in eachindex(bary))
@printf("Estimated area = %f",Aest)

bar!(barx,bary;bar_width=0.5,alpha=0.5,label="boxes")

```
Obviously the first three rectangles have more area than the region under the curve, because the first three include area outside the region. The fourth rectangle underestimates its area, but by a relatively small amount. The overall estimate is an overestimate of the area just based on the visual inspection alone. 

What would happen if we made the width of the bars an infinitesimal $dx$ and used $N=2/dx$ bars?

Let's zoom into just one bar:
```{julia}

x = collect(.75:.05:1.75)
plot(x,sin.(x); legend=false)
bar!([1.25],[sin(1.5)]; bar_width=0.5,alpha=0.5)
bar!([1.25],[sin(1)]; bar_width=0.5, alpha=0.5)
annotate!(1.55,.92,text("dy"))
```
We show two possible bars in this case. The red bar extends up to the maximum value that $\sin(x)$ takes on over the interval [1,1.5] and the green bar extends up to the minimum value that the function takes over that same interval. The area under the curve is clearly more than the area of the green bar, but less than the area of the red bar. The error is in some sense related to the height of the region $dy$

Let's assume the function is **continuous**. We can **define**: **"A standard function is continuous if it doesn't change by more than an infinitesimal amount when we change the input value by an infinitesimal amount".** In other words, if we make the width an infinitesimal, and the function is continuous, then the value of the $dy$ is also an infinitesimal.

## The total area:

Let's add up the area of the bars if we use infinitesimal bars. Remember we are adding up area between x = 0 and x = 2 by splitting this into $2/dx$ little bars (round off to the nearest integer, which is a nonstandard integer because $dx$ is infinitesimal)

$$\sum_{i=1}^{2/dx}f(0+idx)dx$$

Each bar has height $f(x_i)$ and width $dx$. For any given bar at location $x_i$ the real area is $(f(x_i)+dy_i)dx$ where $dy_i$ is some infinitesimal difference between the correct height needed to get the real area of the region under the function, vs the height of the function at the left edge.

The error in our sum is therefore

$$\sum_{i=1}^{2/dx} dy_i dx$$

There are $2/dx$ terms and each one is smaller than $\max(dy_i) dx$ so this is obviously smaller than $2/dx \max(dy_i) dx$ which is $2 \max{dy_i}$ which is an infinitesimal.

By choosing the width of the bars to be an infinitesimal we guarantee that for continuous functions the error in our sum is at most an infinitesimal. So let's define the area to be equal to the standard part of the sum. We call this the "integral" and write it using an elongated S shape 

$$\int$$

Let's define our integral as:

$$A = \int_a^b\sin(x) dx = st\left(\sum_{i=1}^{(b-a)/dx}\sin(a+idx) dx\right)$$

Note that if the function is discontinuous at a standard number N of points, then we will have standard sized errors at those points, the $dy$ values will not be infinitesimal there. But each of these $dy$ values will be multiplied by the infinitesimal $dx$ and there will be a standard number N of them. The sum of these special errors will be less than $N\max(dy)dx$ which is still infinitesimal. So we can "integrate" across a finite standard number of discontinuities without problems. There are other ways to define slightly more general integrals which can integrate a wider variety of functions, but these are not important at this stage of learning.



[^existsNS]: The axioms of IST are the **Idealization**, **Standardization**, and
    **Transfer** axioms.
    Details are available in Edward Nelson's publications, but Roughly, the Transfer axiom says that if something is true about every standard number, then it is true about all numbers. The standard numbers are "witnesses" to the property of interest, if they all confirm the property, then all numbers must have this property even nonstandard ones.

    The Idealization principle says roughly that if you look at standard finite sets of numbers and can always find a special value y such that some property A holds, then you can find such a y for all standard numbers.

    The Standardization principle says roughly that if you have a standard set X and you specify a subset of X in terms of those members that have property A, which can be a nonstandard property, then there is a standard set Y that contains all those X values that have that property. However it may contain nonstandard values which don't have that property.

    From these axioms it is easy to prove that there is a nonstandard positive integer. Imagine we take a standard finite set of positive integers. Since this set is finite we can find the maximum integer N and we can find N+1 which is bigger than any element of the set. Since this is true for every standard finite set of integers, it must be true for all standard integers. Therefore there is an integer which is bigger than all standard integers.

[^proofInftsml]: We can prove that an infinitesimal greater than zero exists. Consider any finite standard set of real numbers greater than 0. Since the set is finite, there is a smallest element x. There also exists y = x/2 which is greater than 0 but smaller than x. This is true for all finite standard sets of positive numbers, therefore it must be true for all positive numbers by the Idealization Axiom. Therefore there exists a number which is greater than 0 but smaller than all standard positive numbers... an infinitesimal!
